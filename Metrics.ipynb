{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metrics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZoORq7OVIVS"
      },
      "source": [
        "Explain in words what accuracy, precision, and recall are.  Describe a situation when you would prefer one to another and where the shortcomings to each lays. \n",
        "\n",
        "Accuracy is a measurement of the positive divided by the negative. \n",
        "Precision is a good measure to determine, when the costs of False Positive is high. Recall actually calculates how many of the Actual Positives our model capture through labeling it as True Positive. If we were analyzing data of a disease then a recall should be used more than a accuracy. With a recall we can get false positives. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy3ezLFPVXfg"
      },
      "source": [
        "What is a confusion matrix?\n",
        "\n",
        "A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J1D3ptoV0DZ"
      },
      "source": [
        "Accuracy = 0\n",
        "Percision = 0\n",
        "Recall = 0\n",
        "TP = 5\n",
        "TN = 5\n",
        "FP = 2\n",
        "FN = 7\n",
        "F1Score = 0\n",
        "\n",
        "#Accuracy\n",
        "Accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
        "\n",
        "#Percision\n",
        "Percision = TP/(TP+FP)\n",
        "\n",
        "#Recall\n",
        "Recall = TP/(TP+FN)\n",
        "\n",
        "#F1 Score\n",
        "F1Score = 2/(1/Percision+1/Recall)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H53hRdU9VeJP"
      },
      "source": [
        "Give your own example of a type 1 and type 2 error\n",
        "\n",
        "Type 1 error - is a false positive\n",
        "\n",
        "Type 2 error â€“ is a false negative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia30HrNcV6dg"
      },
      "source": [
        "Why do we use train.test,split() function from Python when analyzing data?  What is the point of splitting data?\n",
        "\n",
        "The train.test,split() function gives us a idea of the general path of data. There are going to be outliers but the majority of data will follow a certain pattern. By splitting the data we minimize the effects of data discrepancies and better understand the characteristics of the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka5mNTMKWEn4"
      },
      "source": [
        "What is the bias vs. variance tradeoff?\n",
        "\n",
        "Bias is the simplifying assumptions made by the model to make the target function easier to approximate. Trade-off is tension between the error introduced by the bias and the variance.\n"
      ]
    }
  ]
}